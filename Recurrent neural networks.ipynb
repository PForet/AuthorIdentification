{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reccurent neural networks\n",
    "\n",
    "## Introduction\n",
    "\n",
    "The purpose of this notebook is to test several types of reccurent neural networks on the Author identification challenge.\n",
    "\n",
    "### Loading the dataset\n",
    "\n",
    "Let's start by loading the dataset and displaying some sentences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id26305</td>\n",
       "      <td>This process, however, afforded me no means of...</td>\n",
       "      <td>EAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id17569</td>\n",
       "      <td>It never once occurred to me that the fumbling...</td>\n",
       "      <td>HPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id11008</td>\n",
       "      <td>In his left hand was a gold snuff box, from wh...</td>\n",
       "      <td>EAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id27763</td>\n",
       "      <td>How lovely is spring As we looked from Windsor...</td>\n",
       "      <td>MWS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id12958</td>\n",
       "      <td>Finding nothing else, not even gold, the Super...</td>\n",
       "      <td>HPL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                               text author\n",
       "0  id26305  This process, however, afforded me no means of...    EAP\n",
       "1  id17569  It never once occurred to me that the fumbling...    HPL\n",
       "2  id11008  In his left hand was a gold snuff box, from wh...    EAP\n",
       "3  id27763  How lovely is spring As we looked from Windsor...    MWS\n",
       "4  id12958  Finding nothing else, not even gold, the Super...    HPL"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id02310</td>\n",
       "      <td>Still, as I urged our leaving Ireland with suc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id24541</td>\n",
       "      <td>If a fire wanted fanning, it could readily be ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id00134</td>\n",
       "      <td>And when they had broken down the frail door t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id27757</td>\n",
       "      <td>While I was thinking how I should possibly man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id04081</td>\n",
       "      <td>I am not sure to what limit his knowledge may ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                               text\n",
       "0  id02310  Still, as I urged our leaving Ireland with suc...\n",
       "1  id24541  If a fire wanted fanning, it could readily be ...\n",
       "2  id00134  And when they had broken down the frail door t...\n",
       "3  id27757  While I was thinking how I should possibly man...\n",
       "4  id04081  I am not sure to what limit his knowledge may ..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "raw_train = pd.read_csv(\"train.csv\")\n",
    "raw_test = pd.read_csv(\"test.csv\")\n",
    "\n",
    "print(\"Train set:\")\n",
    "display(raw_train.head())\n",
    "\n",
    "print(\"Test set:\")\n",
    "display(raw_test.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can extract the labels from the training dataframe, and convert the remaining column into an array of strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some tokenized sentences from train:\n",
      "[ 'This process, however, afforded me no means of ascertaining the dimensions of my dungeon; as I might make its circuit, and return to the point whence I set out, without being aware of the fact; so perfectly uniform seemed the wall.'\n",
      " 'It never once occurred to me that the fumbling might be a mere mistake.']\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train = raw_train['text'].values, raw_train['author'].values\n",
    "X_test = raw_test['text']\n",
    "\n",
    "print(\"Some tokenized sentences from train:\")\n",
    "print(X_train[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now use scikit's `CountVectorizer` to produce a one hot encoding of our sentences, where each sentence is mapped to a vector containing zeros the corresponding word is not in the sentence) and ones (the corresponding word is in the sentence) . Tokenization is performed automatically. This function return a sparse matrix.\n",
    "We then performe a tf/idf transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "X_train = vectorizer.fit_transform(X_train)\n",
    "X_test = vectorizer.transform(X_test)\n",
    "\n",
    "tf_transformer = TfidfTransformer(use_idf=True).fit(X_train)\n",
    "X_train_tfidf = tf_transformer.transform(X_train)\n",
    "X_test_tfidf = tf_transformer.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a simple one-hot encoder for our labels, and split the inputs and labels into a training and a validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def simple_encoder(y):\n",
    "    keys = {'EAP':[1,0,0], 'HPL':[0,1,0], 'MWS':[0,0,1]}\n",
    "    return map(lambda x: keys[x], y)\n",
    "\n",
    "X_learn_tfidf, X_val_tfidf, y_learn, y_val = train_test_split(X_train_tfidf, y_train, random_state=0)\n",
    "y_learn, y_val = simple_encoder(y_learn), simple_encoder(y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a naive Bayesian classifier to use it as a benchmark for our more complex models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import log_loss\n",
    "import numpy as np\n",
    "\n",
    "gnb =  MultinomialNB()\n",
    "gnb.fit(X_learn_tfidf, np.argmax(y_learn, axis=1))\n",
    "prediction = gnb.predict_proba(X_val_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we assess the accuracy and the multiclass logloss of our predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of 0.809601634321 on the validation set\n",
      "Multiclass log loss of 0.613639775439 on the validation set\n"
     ]
    }
   ],
   "source": [
    "def assess_performance(predicted_proba):\n",
    "    accuracy = accuracy_score(np.argmax(y_val, axis=1), np.argmax(predicted_proba, axis=1))\n",
    "    multiclass_log_loss = log_loss(np.argmax(y_val, axis=1), predicted_proba)\n",
    "    print(\"Accuracy of {} on the validation set\".format(accuracy))\n",
    "    print(\"Multiclass log loss of {} on the validation set\".format(multiclass_log_loss))\n",
    "    \n",
    "assess_performance(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not too bad !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "X_learn_tfidf, X_val_tfidf = X_learn_tfidf.todense(), X_val_tfidf.todense()\n",
    "\n",
    "print(X_learn_tfidf[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-mlogloss:1.02882\ttest-mlogloss:1.04816\n",
      "[1]\ttrain-mlogloss:0.973694\ttest-mlogloss:1.01029\n",
      "[2]\ttrain-mlogloss:0.930061\ttest-mlogloss:0.980565\n",
      "[3]\ttrain-mlogloss:0.893394\ttest-mlogloss:0.956907\n",
      "[4]\ttrain-mlogloss:0.859228\ttest-mlogloss:0.937623\n",
      "[5]\ttrain-mlogloss:0.830139\ttest-mlogloss:0.920776\n",
      "[6]\ttrain-mlogloss:0.804961\ttest-mlogloss:0.906962\n",
      "[7]\ttrain-mlogloss:0.782397\ttest-mlogloss:0.894857\n",
      "[8]\ttrain-mlogloss:0.762067\ttest-mlogloss:0.883999\n",
      "[9]\ttrain-mlogloss:0.744574\ttest-mlogloss:0.873654\n",
      "[10]\ttrain-mlogloss:0.725952\ttest-mlogloss:0.864393\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "xg_train = xgb.DMatrix(X_learn_tfidf, label=np.argmax(y_learn, axis=1))\n",
    "xg_test = xgb.DMatrix(X_val_tfidf, label=np.argmax(y_val, axis=1))\n",
    "# setup parameters for xgboost\n",
    "param = {}\n",
    "# use softmax multi-class classification\n",
    "param['objective'] = 'multi:softprob'\n",
    "param['eval_metric'] = 'mlogloss'\n",
    "# scale weight of positive examples\n",
    "param['eta'] = 0.2\n",
    "param['max_depth'] = 12\n",
    "param['nthread'] = 8\n",
    "param['num_class'] = 3\n",
    "\n",
    "watchlist = [(xg_train, 'train'), (xg_test, 'test')]\n",
    "num_round = 30\n",
    "\n",
    "bst = xgb.train(param, xg_train, num_round, watchlist)\n",
    "# Note: this convention has been changed since xgboost-unity\n",
    "# get prediction, this is in 1D array, need reshape to (ndata, nclass)\n",
    "pred_prob = bst.predict(xg_test).reshape(len(y_val), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of 0.58835546476 on the validation set\n",
      "Multiclass log loss of 0.978218757546 on the validation set\n"
     ]
    }
   ],
   "source": [
    "assess_performance(pred_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 20000)             501380000 \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1000)              20001000  \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 3)                 3003      \n",
      "=================================================================\n",
      "Total params: 521,384,003\n",
      "Trainable params: 521,384,003\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "\n",
    "m1 = Sequential()\n",
    "m1.add(Dense(20000, input_shape=(X_learn_tfidf.shape[1],), activation='softmax'))\n",
    "m1.add(Dense(1000, activation='softmax'))\n",
    "m1.add(Dense(3, activation='softmax'))\n",
    "\n",
    "m1.summary()\n",
    "m1.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 14684 samples, validate on 4895 samples\n",
      "Epoch 1/4\n",
      "  416/14684 [..............................] - ETA: 12086s - loss: 1.0970 - acc: 0.3894"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint \n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='weights.best.hdf5', \n",
    "                               verbose=1, save_best_only=True)\n",
    "\n",
    "m1.fit(X_learn_tfidf, y_learn, validation_data=(X_val_tfidf, y_val), epochs=4, callbacks=[checkpointer])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
